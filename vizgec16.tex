\documentclass{sig-alternate}

% *** SPECIALIZED LIST PACKAGES ***
%
\usepackage{algorithmic}

\usepackage{array}

% *** PDF, URL AND HYPERLINK PACKAGES ***
%
\usepackage{url}

\begin{document}

% Copyright
\CopyrightYear{2016}
\setcopyright{acmlicensed}
\conferenceinfo{GECCO'16 Companion,}{July 20 - 24, 2016, Denver, CO, USA}
\isbn{978-1-4503-4323-7/16/07}\acmPrice{\$15.00}
\doi{http://dx.doi.org/10.1145/2908961.2931742}
% --- End of Author Metadata ---

\title{Visualizing for success: How can we make the user more efficient in
  interactive evolutionary algorithms?}
%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{3} 
\author{
\alignauthor
Juan-J.~Merelo\titlenote{Corresponding author}\\
\affaddr{Dept. of Computer Architecture and Technology and CITIC}\\
\affaddr{University of Granada, Granada, Spain} \\
\email{jmerelo@ugr.es}
\alignauthor
Mario Garc\'ia-Valdez \\
\affaddr{Dept. of Graduate Studies}\\
\affaddr{ Instituto Tecnol\'ogico de Tijuana, Tijuana, Mexico}\\
\email{mario@tectijuana.edu.mx}
\alignauthor
Carlos Cotta\\
\affaddr{Dept. LCC, ETSI Inform\'atica}\\
\affaddr{ Universidad de M\'alaga, M\'alaga, Spain}\\
\email{ccottap@lcc.uma.es}
}

\maketitle


%\keywords{Volunteer computing, distributed computing, cloud computing,
%visualization}


%---------------------------------------------------------------
\section{Introduction}

The main objective in volunteer computing systems is to get
users to contribute to the experiment with as much time as it is
possible. In the case of systems such as NodIO \cite{DBLP:conf/gecco/GuervosG15}, 
a
web-service based system which
provides a minimal infrastructure to support pool-based distributed
evolutionary computing experiments, there is another issue with the 
user: the fact that there is some interaction that can be done besides
simply loading the web page once. 

NodIO 
has been used for volunteer computing experiments by
embedding an island-based evolutionary algorithm inside a web page and
making them interchange information via the NodIO server, in a
spontaneous and eventually, since all islands communicate via the
server, panmictic distributed evolutionary
algorithm. In the experiments we have carried out so far we have
realized %that the way the user perceives the state of the algorithm
%can make him or her act in several ways. For instance, reloading the
%page, in which case a new population will be generated, with the best
%% Maybe make it clearer: with the best of the new individuals
%individuals being sent to the pool adding to the diversity of that
%pool. The user can also load the webpage in several browsers or
%browser tabs thus is adding more computing power and seeing how the 
%solution spreads from one island to the other. In any case, we have noticed
that the user is spontaneously making it an {\em interactive}
algorithm %\cite{takagi01interactive}, 
by applying {\em hypermutation} 
operators or even {\em distributing} the population themselves if the 
performance of their machine allows them to do so. 
%What is an example of hypermutation? When they reboot the algorithms? 
%maybe give an example:
%making it an {\em interactive} algorithm by applying {\em hypermutation}  operators
However, it will be impossible for the user to perceive what is
happening if the visualization does not convey that information in a
way that (1) can be first understood by anyone without using any technical
terms and (2) does not add too much overhead to the algorithm
itself. As far as we know, the problem of visualizing an evolutionary
algorithm so that the non-technical and spontaneous user can help it
find the solution faster has not been fully solved. We have made several
attempts that we will present in this paper, but this paper is
basically a request for comments during the workshop and later on so
that the scientific community understands the basis of this problem
and can also design their own solutions for it. To reach this goal
other aspects of the design must also be  addressed in order to
improve the overall usabilty of the system.

%That is why the rest of the paper will be devoted to a short state of
%the art, an exposition of our efforts so far and finally instead of
%conclusions several research questions that we hope are the bases for
%a discussion of this issue.
%
%
%NodIO \cite{DBLP:conf/gecco/GuervosG15} is a
%web-services based system that provides a basic platform to run distributed evolutionary
%computing experiments, including volunteer computing systems, with a
%low overhead.  
 
\begin{figure*}[!htb]
\centering
\includegraphics[width=0.9\linewidth]{all.png}
\caption{The three panels showing the latest fitness, the cache size
  and the best chromosome using 4 shades from white to black to
  represent the number of ones in every block in the Trap
  problem at the top; at bottom, the panel showing 5
  black bars indicating that all but 4  traps have been found. \label{fig:all}}
\end{figure*}
%
The client displays three panels, showing three different
visualizations of the evolutionary algorithm. Two of them have been
kept fixed for all experiments, and they are shown in Figure
\ref{fig:all}. The top panels show, to the right, the fitness in the
last 5000 generations at 100 generations interval. The bottom panel
shows a visualization of the best individual, using blocks that
represent the number of ones in 4-bit blocks with different shades 
that represent their block fitness, from 0 (transparent) to 2
(black). 1 is the intermediate fitness, achieved with all 0s, and it
is represented by dark gray. 

From the point of view of the user, this is probably one of the best
indicators of the stagnation of the simulation. %The most likely
%situation is to have that panel stuck with all blocks in black except
%one in gray, with the fitness stuck at 99. If that happens for a long
%time, it is almost impossible for a single island to find the
%solution, because it is stuck in a local minimum from which it is
%impossible to get out with a single mutation; it needs a string of
%favorable mutations, all of them having a lower fitness. So in
%principle that situation 
It could help the user to restart the simulation
in that case, but it is almost impossible for the user to forecast
when that will be happening to avoid it, either by restarting or by
starting new islands in other browser tabs. 

This information might be redundant with that shown in the fitness
panel. However, it helps when you
have several windows, side by side. If the best chromosome is the same
in both, not only a single island is stuck, but the whole number of
islands contributing are. That happens usually when there is a single
island running for some time in that situation and all of a sudden
several other volunteers come in. As soon as they start to receive
random individuals from the cache, they are bound to get that {\em
  super} individual, which will eventually {\em invade} the
population, crashing global diversity. The best situation is when
several individuals arrive at short intervals, contributing diversity
but also individuals that are not so different; by the {\em
  intermediate disturbance hypothesis} that
situation will boost the performance of the whole system. However, the
user in general will run a single tab, so they will not know that is
happening; this is a kind of information that we would need to convey
to the user by way of visualization. But that is why we use the third
panel. 

Initially we used as third panel the number of IPs that had
participated so far. %, shown in Figure \ref{fig:howmany}. 
This was
mainly for the benefit of us, not really the user; it was a way of
knowing the impact of some particular announcement and also to see how
many users were there at a particular time. However, the user could
gather no information either about his particular involvement or about
the progress of the simulation. Besides, it was the {\em total} number
of IPs from the beginning of the batch of experiments, it did not show
the instantaneous, or in the last minutes, number of participating
IPs. That is why we opted to change that visualization to a new one
that at least included some information on it. 

That is not exactly what is shown in the graph, that
shows the cache size. However, if you combine this panel with the
other, and the fitness panel and the chromosome panel shows some
change, you will see if that change is incorporated to the cache if
that changes size. If the cache remains the same, no new individuals
are being generated and again you can have a perspective of the whole
experiment being stagnated in a single view; the user can then decide
to restart or also to create new populations. It is still a poor way
of conveying global information and it requires a certain amount of
information given to the user so that he or she can understand what is
going on.

%In order to see whether this new panel was more effective from the
%point of view of the user interaction than the previous one, we
%measured the amount of {\em reboots}, that is, new initializations of
%population by the user, either by restarting one window or starting
%new ones. In order to measure this effectivity, we measured the
%amount of reboots per IP. When the first graph was used, the average
%was 0.74; the second graph, depending on the batch of experiments,
%registered averages over 1, 1.58 in a first batch and 1.16 in a second
%batch, both carried out in the month of February and March, indicating
%an average of more than 1 reboot per user. This might indicate that
%showing more information to the user, specially about the global
%progress of the experiment, encourages them to act on it, by using the
%only tool they have: reloading the page, thus restarting the
%experiment, or loading it in new pages. And that is also the reason
%why we think that using innovative ways of visualization will
%encourage them to interact even more with it, turning it into a truly
%interactive experiment. 


%---------------------------------------------------------------
\section{What can be visualized and how it could help}
\label{sec:conclusion}

For the time being, the only possible interactions the user has is to start  or
restart new islands. However, this does not need to be the only way the user 
can help the simulation. Even keeping the user interface as simple as
possible, other possibilities could include: (i) {\em killing} the best individual, thus immediately creating
  diversity by forcing the rest to compete; (ii) increasing or decreasing the population size. A bigger
  population will have higher initial diversity; (iii) increasing or decreasing the mutation or crossover rate. For the time being,
  bitflip mutation is used on every new generated individual. 
%  Maybe it
%  could be decreased to a lower percentage, or increase the number of
%  bits flipped for every individual generated.

However, even if whatever the user does will contribute to diversity,
if it is done blindly it will explore more than exploit and thus be a
waste of computational resources. That is why there are several
possible ways of showing progress and diversity%, which is a predictor for future progress
: (i) represent the convergence of the population towards a single
  individual by showing, using grayscale, the uniformity of values for
  all bits; %. This can be represented alongside the best one, or maybe
  %instead of the best one.
(ii) represent global diversity by having a measure of compression
  entropy plotted, instead or alongside the cache size.

This can be complemented by other visualization techniques, such as 
(i) use Twitter or a Telegram channel to show the progress of
  the current experiment, or making calls when a new experiment has
  started to have an early infusion of diversity, 
(ii) represent the progress of the particular user against the rest
  of the users, showing the fitness of every one, for instance, or the
  time every one has spent represented by the number of PUTs that have
  been made,
%  The fitness has the problem that, after certain time, all
%  fitness would be the same. However, this can be seen as an indicator
%  that the experiment has stagnated and thus a restart has to be made.
(iii) keep past history and represent the current experiment comparing its
  progress to the progress of previous ones,
(iv) show global fitness alongside local fitness, 
%Once again, the 
%  best global fitness (as contained in the cache) is not the best predictor
%  of future progress, since the nature of the problem will mean that
%  reaching the global fitness will, in fact, mean that the population
%  has converged to a local minimum

More important maybe that the data itself is the way of representing
it. A visualization that shows how well or badly the global algorithm
is doing would help to encourage the users to take measures to improve
the situation. That is why we finish this paper with a series of
research questions

\section{Research questions}

With this paper we would like to raise a series of research questions
on the good use of visualization of evolutionary algorithms in
distributed voluntary evolutionary computing experiments:
%. These are
%questions to be discussed on the workshop itself, or as comments when
%this paper will be published online. 
%We are also expecting comments in
%the repository where this paper has been elaborated in GitHub
%\footnote{\url{https://github.com/JJ/vizgec2016/}}. Following an Open Science
%policy, most papers by our research groups are created in an open
%repository that is open for collaboration and discussion.
%\begin{enumerate}
(i) how can we represent in a meaningful but at the same time simple
  way the global progress of the simulation so that the user can take
  action if he needs to?
(ii) how can we also represent diversity so that it conveys to the
  user the fact that he or she can help by taking whatever measures
  the client allows, even a simple restart?
(iii) should we use some kind of reinforcement, indicating whether the
  individuals created locally by the user have helped find the global solution?
(iv) how could we gamify participation so that, at the same time,
  cheating is discouraged?
(v) how can we implement this ideas with a minimum overhead to the system?  
(vi) Finally, how can any of these measures be taken so that it is
  not a impossible overhead for the algorithm itself?

%---------------------------------------------------------------
\subsection*{Acknowledgments}
 
This work has been supported in part by
TIN2014-56494-C4-\{1,3\}-P (Spanish Ministry of Economy and
Competitivity), PROY-PP2015-06 (Plan Propio 2015 UGR). Additional
support was received by 
Projects 5622.15-P (ITM) DNEMESIS P10-TIC-6083 (Junta de
Andaluc\'{\i}a) and PROINNOVA 2016: 230630 (CONACYT). 

\bibliographystyle{abbrv}
\bibliography{carlos,geneura,volunteer,pool}

\end{document}

%%% Local Variables:
%%% ispell-local-dictionary: "english"
%%% End:
